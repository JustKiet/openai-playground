{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16119186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Generator, Optional, Callable, Any, Generic, TypedDict, Required, TypeVar, Literal\n",
    "from pydantic.dataclasses import dataclass\n",
    "from openai.types.responses import ResponseInputItemParam, ResponseFunctionToolCallParam\n",
    "from openai.types.responses.response_output_message_param import ResponseOutputMessageParam\n",
    "from openai.types.responses.response_reasoning_item_param import ResponseReasoningItemParam, Summary\n",
    "from openai.types.responses.response_input_item_param import FunctionCallOutput\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "MessageLike = ResponseInputItemParam\n",
    "\n",
    "class StreamingEventType(Enum):\n",
    "    REASONING_TOKEN = \"reasoning_token\"\n",
    "    REASONING = \"reasoning\"\n",
    "    TOKEN = \"token\"\n",
    "    TOOL_CALL = \"tool_call\"\n",
    "    TOOL_RESULT = \"tool_result\"\n",
    "    COMPLETED = \"completed\"\n",
    "\n",
    "class AgentStreamingEventType(Enum):\n",
    "    REASONING = \"reasoning\"\n",
    "    TOKEN = \"token\"\n",
    "    ACTION = \"action\"\n",
    "    ACTION_RESULT = \"action_result\"\n",
    "    COMPLETED = \"completed\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ToolCall:\n",
    "    name: str\n",
    "    tool_call_id: str\n",
    "    arguments: dict[str, Any]\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    conversation_id: str\n",
    "    user_query: str\n",
    "    messages: list[MessageLike]\n",
    "    tools: set[Callable[..., str]]\n",
    "\n",
    "@dataclass\n",
    "class LLMStreamingEvent:\n",
    "    event: StreamingEventType\n",
    "    data: str\n",
    "    tool_call_id: str | None = None\n",
    "    tool_calls: list[ToolCall] | None = None\n",
    "\n",
    "@dataclass\n",
    "class AgentStreamingEvent:\n",
    "    event: AgentStreamingEventType\n",
    "    data: str\n",
    "    action_id: str | None = None\n",
    "\n",
    "class LLM(ABC):\n",
    "    @abstractmethod\n",
    "    def generate_text(self, messages: list[MessageLike], tools: Optional[set[Callable[..., str]]] = None) -> Generator[LLMStreamingEvent, None, None]:\n",
    "        \"\"\"Generate text based on the given prompt.\"\"\"\n",
    "        pass\n",
    "\n",
    "class EmbeddingModel(ABC):\n",
    "    @abstractmethod\n",
    "    def embed_texts(self, texts: list[str]) -> list[list[float]]:\n",
    "        \"\"\"Generate embedding for the given texts.\"\"\"\n",
    "        pass\n",
    "\n",
    "TIn = TypeVar(\"TIn\")\n",
    "TOut = TypeVar(\"TOut\")\n",
    "TNext = TypeVar(\"TNext\")\n",
    "\n",
    "class Handler(ABC, Generic[TIn, TOut]):\n",
    "    @abstractmethod\n",
    "    def process(self, input: TIn) -> TOut:\n",
    "        pass\n",
    "\n",
    "    def handle(self, input: TIn) -> TOut:\n",
    "        return self.process(input)\n",
    "\n",
    "    def then(self, next_handler: Handler[TOut, TNext]) -> Chain[TIn, TNext]:\n",
    "        return Chain(self, next_handler)\n",
    "\n",
    "class Chain(Handler[TIn, TOut]):\n",
    "    \"\"\"Represents two linked handlers as a single unit.\"\"\"\n",
    "    def __init__(self, first: Handler[TIn, TNext], second: Handler[TNext, TOut]):\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "\n",
    "    def process(self, input: TIn) -> TOut:\n",
    "        intermediate = self.first.handle(input)\n",
    "        return self.second.handle(intermediate)\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "class Command(ABC, Generic[T]):\n",
    "    @abstractmethod\n",
    "    def exec(self, input: T) -> None:\n",
    "        pass\n",
    "\n",
    "class ToolHandler(Handler[ToolCall, str]):\n",
    "    def __init__(\n",
    "        self, \n",
    "        tools: set[Callable[..., str]],\n",
    "        on_error: Optional[Callable[[ToolCall, Exception], str]] = None,\n",
    "    ) -> None:\n",
    "        self.tool_mappings: dict[str, Callable[..., str]] = {}\n",
    "        self.add_tools(tools)\n",
    "        self.on_error = on_error\n",
    "\n",
    "    @property\n",
    "    def tools(self) -> set[Callable[..., str]]:\n",
    "        return set(self.tool_mappings.values())\n",
    "    \n",
    "    @property\n",
    "    def tool_names(self) -> set[str]:\n",
    "        return set(self.tool_mappings.keys())\n",
    "    \n",
    "    def clear_tools(self) -> None:\n",
    "        \"\"\"Remove all tools from the handler.\"\"\"\n",
    "        self.tool_mappings = {}\n",
    "    \n",
    "    def get_tool(self, name: str) -> Optional[Callable[..., str]]:\n",
    "        return self.tool_mappings.get(name)\n",
    "        \n",
    "    def add_tools(self, tools: set[Callable[..., str]]) -> None:\n",
    "        \"\"\"Add tools to the handler.\"\"\"\n",
    "        for func_tool in tools:\n",
    "            if func_tool.__name__ in self.tool_mappings:\n",
    "                continue\n",
    "            self.tool_mappings[func_tool.__name__] = func_tool\n",
    "\n",
    "    def set_tools(self, tools: set[Callable[..., str]]) -> None:\n",
    "        \"\"\"Set the tools for the handler, replacing any existing tools.\"\"\"\n",
    "        self.clear_tools()\n",
    "        self.add_tools(tools)\n",
    "\n",
    "    def update_tool(self, tool: Callable[..., str]) -> None:\n",
    "        \"\"\"Update or add a single tool in the handler.\"\"\"\n",
    "        self.tool_mappings[tool.__name__] = tool\n",
    "\n",
    "    def remove_tool(self, name: str) -> None:\n",
    "        \"\"\"Remove a tool by name from the handler.\"\"\"\n",
    "        if name in self.tool_mappings:\n",
    "            del self.tool_mappings[name]\n",
    "\n",
    "    def process(self, input: ToolCall) -> str:\n",
    "        return self.execute_tool(input)\n",
    "\n",
    "    def execute_tool(self, tool_call: ToolCall) -> str:\n",
    "        tool = self.tool_mappings.get(tool_call.name)\n",
    "        if not tool:\n",
    "            return f\"Error: Tool '{tool_call.name}' not found.\"\n",
    "\n",
    "        try:\n",
    "            return tool(**tool_call.arguments)\n",
    "        except Exception as e:\n",
    "            if self.on_error:\n",
    "                return self.on_error(tool_call, e)\n",
    "            else:\n",
    "                return f\"Error executing tool '{tool_call.name}': {str(e)}\"\n",
    "    \n",
    "class ToolRouter(ToolHandler):\n",
    "    \"\"\"Base class for tool routing based on queries.\"\"\"\n",
    "    @abstractmethod\n",
    "    def retrieve(self, query: str) -> set[Callable[..., str]]:\n",
    "        \"\"\"Retrieve appropriate tools based on the query.\"\"\"\n",
    "        pass\n",
    "\n",
    "ToolUseBehavior = Literal[\n",
    "    \"stop_on_tool_call\", \n",
    "    \"stop_on_tool_result\", \n",
    "    \"auto\"\n",
    "]\n",
    "\n",
    "ToolName = str\n",
    "\n",
    "class Agent:\n",
    "    def __init__(\n",
    "        self, \n",
    "        llm: LLM, \n",
    "        tool_handler: ToolHandler,\n",
    "        tool_use_behavior: Optional[ToolUseBehavior] = \"auto\",\n",
    "        on_tool_call: Optional[dict[ToolName, Command[ToolCall]]] = None,\n",
    "        on_tool_result: Optional[dict[ToolName, Command[tuple[ToolCall, str]]]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.llm = llm\n",
    "        self.tool_handler = tool_handler\n",
    "        self.tool_use_behavior = tool_use_behavior\n",
    "\n",
    "        self.on_tool_call = on_tool_call\n",
    "        self.on_tool_result = on_tool_result\n",
    "\n",
    "    def add_tools(self, tools: set[Callable[..., str]]) -> None:\n",
    "        \"\"\"Add tools to the agent.\"\"\"\n",
    "        self.tool_handler.add_tools(tools)\n",
    "\n",
    "    def run(self, messages: list[MessageLike]) -> Generator[LLMStreamingEvent, None, None]:\n",
    "        \"\"\"Run the agent with the given prompt.\"\"\"\n",
    "        while True:\n",
    "            for delta in self.llm.generate_text(messages, tools=self.tool_handler.tools):\n",
    "                if delta.event == StreamingEventType.REASONING_TOKEN:\n",
    "                    yield delta\n",
    "                if delta.event == StreamingEventType.REASONING:\n",
    "                    yield delta\n",
    "                    messages.append( \n",
    "                        ResponseReasoningItemParam( # type: ignore\n",
    "                            type=\"reasoning\",\n",
    "                            summary=[Summary(\n",
    "                                type=\"summary_text\",\n",
    "                                text=delta.data\n",
    "                            )],\n",
    "                        )\n",
    "                    )\n",
    "                elif delta.event == StreamingEventType.TOOL_CALL and delta.tool_calls:\n",
    "                    yield delta\n",
    "                    \n",
    "                    for tool_call in delta.tool_calls:\n",
    "                        messages.append(\n",
    "                            ResponseFunctionToolCallParam(\n",
    "                                type=\"function_call\",\n",
    "                                name=tool_call.name,\n",
    "                                arguments=json.dumps(tool_call.arguments),\n",
    "                                call_id=tool_call.tool_call_id,\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                        if self.on_tool_call:\n",
    "                            command = self.on_tool_call.get(tool_call.name)\n",
    "                            if command:\n",
    "                                command.exec(tool_call)\n",
    "                    \n",
    "                    if self.tool_use_behavior == \"stop_before\":\n",
    "                        return\n",
    "                    \n",
    "                    for tool_call in delta.tool_calls:\n",
    "                        tool_result = self.tool_handler.execute_tool(tool_call)\n",
    "                        yield LLMStreamingEvent(\n",
    "                            event=StreamingEventType.TOOL_RESULT,\n",
    "                            tool_call_id=tool_call.tool_call_id,\n",
    "                            data=tool_result,\n",
    "                        )\n",
    "                        messages.append(\n",
    "                            FunctionCallOutput(\n",
    "                                type=\"function_call_output\",\n",
    "                                output=tool_result,\n",
    "                                call_id=tool_call.tool_call_id,\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                        if self.on_tool_result:\n",
    "                            command = self.on_tool_result.get(tool_call.name)\n",
    "                            if command:\n",
    "                                command.exec((tool_call, tool_result))\n",
    "                        \n",
    "                    if self.tool_use_behavior == \"stop_after\":\n",
    "                        return\n",
    "                elif delta.event == StreamingEventType.COMPLETED:\n",
    "                    yield LLMStreamingEvent(\n",
    "                        event=StreamingEventType.COMPLETED,\n",
    "                        data=delta.data,\n",
    "                    )\n",
    "                    messages.append(\n",
    "                        ResponseOutputMessageParam( # type: ignore\n",
    "                            role=\"assistant\",\n",
    "                            content=delta.data\n",
    "                        )\n",
    "                    )\n",
    "                    return\n",
    "                elif delta.event == StreamingEventType.TOKEN:\n",
    "                    yield LLMStreamingEvent(\n",
    "                        event=StreamingEventType.TOKEN,\n",
    "                        data=delta.data,\n",
    "                    )\n",
    "                \n",
    "class ConversationRepository(ABC):\n",
    "    @abstractmethod\n",
    "    def get_conversation_history(self, conversation_id: str) -> list[MessageLike]:\n",
    "        \"\"\"Retrieve the conversation history for the given conversation ID.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_messages(self, conversation_id: str, messages: list[MessageLike]) -> None:\n",
    "        \"\"\"Add messages to the conversation history.\"\"\"\n",
    "        pass\n",
    "\n",
    "class ContextPrepareParam(TypedDict):\n",
    "    conversation_id: Required[str]\n",
    "    query: Required[str]\n",
    "\n",
    "class ContextMiddleware(Handler[ContextPrepareParam, Context]):\n",
    "    def __init__(\n",
    "        self, \n",
    "        conversation_repository: ConversationRepository,\n",
    "        tool_router: ToolRouter\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.conversation_repository = conversation_repository\n",
    "        self.tool_router = tool_router\n",
    "        \n",
    "    def process(self, input: ContextPrepareParam) -> Context:\n",
    "        \"\"\"Prepare context for the LLM based on conversation ID and query.\"\"\"\n",
    "        history = self.conversation_repository.get_conversation_history(input[\"conversation_id\"])\n",
    "        tools = self.tool_router.retrieve(input[\"query\"])\n",
    "\n",
    "        history.append({\"role\": \"user\", \"content\": input[\"query\"]})\n",
    "        \n",
    "        return Context(\n",
    "            conversation_id=input[\"conversation_id\"],\n",
    "            user_query=input[\"query\"],\n",
    "            messages=history,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "class AgentService:\n",
    "    def __init__(\n",
    "        self, \n",
    "        agent: Agent,\n",
    "        context_middleware: ContextMiddleware\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.agent = agent\n",
    "        self.context_middleware = context_middleware\n",
    "\n",
    "    def handle_request(self, conversation_id: str, query: str) -> Generator[AgentStreamingEvent, None, None]:\n",
    "        \"\"\"Handle the request by preparing context and generating text.\"\"\"\n",
    "        context = self.context_middleware.process({\"conversation_id\": conversation_id, \"query\": query})\n",
    "        self.agent.add_tools(context.tools)\n",
    "        for delta in self.agent.run(context.messages):\n",
    "            if delta.event == StreamingEventType.TOOL_CALL and delta.tool_calls:\n",
    "                for tool_call in delta.tool_calls:\n",
    "                    yield AgentStreamingEvent(\n",
    "                        event=AgentStreamingEventType.ACTION,\n",
    "                        data=f\"Calling tool {tool_call.name} with arguments {tool_call.arguments}\",\n",
    "                        action_id=tool_call.tool_call_id or \"\"\n",
    "                    )\n",
    "            \n",
    "            elif delta.event == StreamingEventType.TOOL_RESULT:\n",
    "                yield AgentStreamingEvent(\n",
    "                    event=AgentStreamingEventType.ACTION_RESULT,\n",
    "                    data=delta.data,\n",
    "                    action_id=delta.tool_call_id or \"\"\n",
    "                )\n",
    "\n",
    "            elif delta.event == StreamingEventType.COMPLETED:\n",
    "                self.context_middleware.conversation_repository.add_messages(\n",
    "                    conversation_id,\n",
    "                    [{\"role\": \"user\", \"content\": query}, {\"role\": \"assistant\", \"content\": delta.data}]\n",
    "                )\n",
    "                yield AgentStreamingEvent(\n",
    "                    event=AgentStreamingEventType.COMPLETED,\n",
    "                    data=delta.data\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                yield AgentStreamingEvent(\n",
    "                    event=AgentStreamingEventType.TOKEN,\n",
    "                    data=delta.data\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cec20ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Fetches the current weather for a given city.\"\"\"\n",
    "    # Placeholder implementation\n",
    "    return f\"The current weather in {city} is sunny with a temperature of 75°F.\"\n",
    "\n",
    "@tool\n",
    "def get_info(user_name: str) -> str:\n",
    "    \"\"\"Fetches information about a user.\"\"\"\n",
    "    # Placeholder implementation\n",
    "    return f\"User {user_name} is a software developer from San Francisco.\"\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-5.1\",\n",
    "    reasoning={\"effort\": \"medium\", \"summary\": \"auto\"},\n",
    "    use_responses_api=True\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather, get_info],\n",
    "    system_prompt=\"You're an assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6adf07ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'rs_0896681f62a5d5fb006926fd7ecd5881a393dfd54aa0556c2d', 'summary': [], 'type': 'reasoning', 'index': 0}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ''}], 'index': 0, 'type': 'reasoning', 'id': 'rs_0896681f62a5d5fb006926fd7ecd5881a393dfd54aa0556c2d'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '**Planning'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' parallel'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' tool'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' usage'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '**\\n\\nThe'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' user'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' is'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' asking'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' for'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' the'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' weather'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' in'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' New'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' York'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' and'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' information'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' about'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' a'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' user'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' named'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' Alice'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '.'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' Since'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' tools'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' are'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' available'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ','}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' I'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' can'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' use'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' them'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' in'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' parallel'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '.'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' I'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '’m'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' thinking'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': \" it's\"}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' effective'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' to'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' call'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' both'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' tools'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' together'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' with'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' multi'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '_tool'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '_use'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '.parallel'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ','}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' specifically'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' \"'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': 'functions'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '.get'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '_weather'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '\"'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' for'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' the'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' weather'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' and'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' \"'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': 'functions'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '.get'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '_info'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '\"'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' for'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' Alice'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': \"'s\"}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' information'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '.'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' Once'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' I'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' get'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' the'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' results'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ','}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' I'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '’ll'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' respond'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' with'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' the'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' details'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '.'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' Let'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '’s'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' get'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' to'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': ' it'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'summary': [{'index': 0, 'type': 'summary_text', 'text': '!'}], 'index': 0, 'type': 'reasoning'}\n",
      "{'type': 'function_call', 'name': 'get_weather', 'arguments': '', 'call_id': 'call_zlRxIpBA1BzsUKoaTPiCZ7gO', 'id': 'fc_0896681f62a5d5fb006926fd827da081a39b746eacfd30053a', 'index': 1}\n",
      "{'type': 'function_call', 'arguments': '{', 'index': 1}\n",
      "{'type': 'function_call', 'arguments': '\"city', 'index': 1}\n",
      "{'type': 'function_call', 'arguments': '\":', 'index': 1}\n",
      "{'type': 'function_call', 'arguments': '\"New', 'index': 1}\n",
      "{'type': 'function_call', 'arguments': ' York', 'index': 1}\n",
      "{'type': 'function_call', 'arguments': '\"}', 'index': 1}\n",
      "{'type': 'function_call', 'name': 'get_info', 'arguments': '', 'call_id': 'call_vHKP0HgudVtHUr7t0utTOix0', 'id': 'fc_0896681f62a5d5fb006926fd8283d081a3ae59ee9a15a591d3', 'index': 2}\n",
      "{'type': 'function_call', 'arguments': '{', 'index': 2}\n",
      "{'type': 'function_call', 'arguments': '\"user', 'index': 2}\n",
      "{'type': 'function_call', 'arguments': '_name', 'index': 2}\n",
      "{'type': 'function_call', 'arguments': '\":', 'index': 2}\n",
      "{'type': 'function_call', 'arguments': '\"Alice', 'index': 2}\n",
      "{'type': 'function_call', 'arguments': '\"}', 'index': 2}\n",
      "{'type': 'text', 'text': 'Here', 'index': 0}\n",
      "{'type': 'text', 'text': '’s', 'index': 0}\n",
      "{'type': 'text', 'text': ' the', 'index': 0}\n",
      "{'type': 'text', 'text': ' information', 'index': 0}\n",
      "{'type': 'text', 'text': ' you', 'index': 0}\n",
      "{'type': 'text', 'text': ' asked', 'index': 0}\n",
      "{'type': 'text', 'text': ' for', 'index': 0}\n",
      "{'type': 'text', 'text': ':\\n\\n', 'index': 0}\n",
      "{'type': 'text', 'text': '-', 'index': 0}\n",
      "{'type': 'text', 'text': ' **', 'index': 0}\n",
      "{'type': 'text', 'text': 'Weather', 'index': 0}\n",
      "{'type': 'text', 'text': ' in', 'index': 0}\n",
      "{'type': 'text', 'text': ' New', 'index': 0}\n",
      "{'type': 'text', 'text': ' York', 'index': 0}\n",
      "{'type': 'text', 'text': ':**', 'index': 0}\n",
      "{'type': 'text', 'text': ' It', 'index': 0}\n",
      "{'type': 'text', 'text': '’s', 'index': 0}\n",
      "{'type': 'text', 'text': ' currently', 'index': 0}\n",
      "{'type': 'text', 'text': ' sunny', 'index': 0}\n",
      "{'type': 'text', 'text': ' with', 'index': 0}\n",
      "{'type': 'text', 'text': ' a', 'index': 0}\n",
      "{'type': 'text', 'text': ' temperature', 'index': 0}\n",
      "{'type': 'text', 'text': ' of', 'index': 0}\n",
      "{'type': 'text', 'text': ' **', 'index': 0}\n",
      "{'type': 'text', 'text': '75', 'index': 0}\n",
      "{'type': 'text', 'text': '°F', 'index': 0}\n",
      "{'type': 'text', 'text': '**', 'index': 0}\n",
      "{'type': 'text', 'text': '.\\n', 'index': 0}\n",
      "{'type': 'text', 'text': '-', 'index': 0}\n",
      "{'type': 'text', 'text': ' **', 'index': 0}\n",
      "{'type': 'text', 'text': 'User', 'index': 0}\n",
      "{'type': 'text', 'text': ' Alice', 'index': 0}\n",
      "{'type': 'text', 'text': ':**', 'index': 0}\n",
      "{'type': 'text', 'text': ' Alice', 'index': 0}\n",
      "{'type': 'text', 'text': ' is', 'index': 0}\n",
      "{'type': 'text', 'text': ' a', 'index': 0}\n",
      "{'type': 'text', 'text': ' **', 'index': 0}\n",
      "{'type': 'text', 'text': 'software', 'index': 0}\n",
      "{'type': 'text', 'text': ' developer', 'index': 0}\n",
      "{'type': 'text', 'text': '**', 'index': 0}\n",
      "{'type': 'text', 'text': ' from', 'index': 0}\n",
      "{'type': 'text', 'text': ' **', 'index': 0}\n",
      "{'type': 'text', 'text': 'San', 'index': 0}\n",
      "{'type': 'text', 'text': ' Francisco', 'index': 0}\n",
      "{'type': 'text', 'text': '**', 'index': 0}\n",
      "{'type': 'text', 'text': '.', 'index': 0}\n",
      "{'type': 'text', 'id': 'msg_0896681f62a5d5fb006926fd84aa8881a3bcb4a6a6ae6b6002', 'index': 0}\n"
     ]
    }
   ],
   "source": [
    "for event_type, (token, _) in agent.stream(\n",
    "    # {\n",
    "    #     \"messages\": [\n",
    "    #         {\"role\": \"user\", \"content\": \"Tell me the difference between MCP and Function Calling API\"}\n",
    "    #     ]\n",
    "    # },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Tell me about the weather in New York and info about user Alice. Think carefully\"}\n",
    "        ]\n",
    "    },\n",
    "    stream_mode=[\"messages\"]\n",
    "):\n",
    "    #print(token, type(token))\n",
    "    delta_content = token.content\n",
    "    if delta_content and isinstance(delta_content, list):\n",
    "        # We can safely assume that there's only going to be 1 item within this list\n",
    "        event = delta_content[0]\n",
    "        print(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53939cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamic-tool-router (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
