{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9074f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8118a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class EmbeddingModel(ABC):\n",
    "    @abstractmethod\n",
    "    def embed_texts(self, texts: list[str]) -> list[list[float]]:\n",
    "        \"\"\"Generate embedding for the given texts.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199d532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIEmbeddingModel(EmbeddingModel):\n",
    "    def __init__(self, model_name: openai.types.EmbeddingModel, api_key: str | None = os.getenv(\"OPENAI_API_KEY\")) -> None:\n",
    "        self.model_name = model_name\n",
    "        self.api_key = api_key \n",
    "        self.client = openai.OpenAI(api_key=self.api_key)\n",
    "\n",
    "    def embed_texts(self, texts: list[str]) -> list[list[float]]:\n",
    "        if not texts:\n",
    "            return []\n",
    "        response = self.client.embeddings.create(\n",
    "            model=self.model_name,\n",
    "            input=texts\n",
    "        )\n",
    "        embeddings = [data.embedding for data in response.data]\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6872be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1: list[float], vec2: list[float]) -> float:\n",
    "    \"\"\"Compute the cosine similarity between two vectors.\"\"\"\n",
    "    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
    "    magnitude1 = sum(a * a for a in vec1) ** 0.5\n",
    "    magnitude2 = sum(b * b for b in vec2) ** 0.5\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0.0\n",
    "    return dot_product / (magnitude1 * magnitude2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ba755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test negation handling\n",
    "embedding_model = OpenAIEmbeddingModel(model_name=\"text-embedding-3-small\")\n",
    "\n",
    "sentences = [\n",
    "    \"Techvify is created in 2019.\",\n",
    "    \"Techvify is not created in 2019.\",\n",
    "    \"Techvify is created in 2025.\"\n",
    "]\n",
    "\n",
    "embedding = embedding_model.embed_texts(sentences)\n",
    "\n",
    "A = embedding[0]\n",
    "A_neg = embedding[1]\n",
    "B = embedding[2]\n",
    "\n",
    "sim_A_B = cosine_similarity(A, B)\n",
    "sim_Aneg_B = cosine_similarity(A_neg, B)\n",
    "\n",
    "print(f\"Cosine similarity between A and B: {sim_A_B}\")\n",
    "print(f\"Cosine similarity between A_neg and B: {sim_Aneg_B}\")\n",
    "\n",
    "if sim_A_B > sim_Aneg_B:\n",
    "    print(\"The embedding model correctly captures negation.\")\n",
    "else:\n",
    "    print(\"The embedding model fails to capture negation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b5301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token usage: CompletionUsage(completion_tokens=14, prompt_tokens=105, total_tokens=119, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "Are the sentences 'Techvify duoc thanh lap vao nam 2019.' and 'Techvify khong duoc thanh lap vao nam 2019.' opposites? True\n",
      "Time taken: 5.789373511999656 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "def is_opposite(text_a: str, text_b: str) -> bool:\n",
    "    \"\"\"Determine if two sentences are opposites using OpenAI's chat completion.\"\"\"\n",
    "    import pydantic\n",
    "\n",
    "    class Classification(pydantic.BaseModel):\n",
    "        is_opposite: bool\n",
    "        is_irrelevant: bool\n",
    "\n",
    "    client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    completion = client.chat.completions.parse(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Are these two text opposites in meaning?\\n1. {text_a}\\n2. {text_b}\"}\n",
    "        ],\n",
    "        response_format=Classification,\n",
    "        max_tokens=100,\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.parsed\n",
    "    usage = completion.usage\n",
    "    print(f\"Token usage: {usage}\")\n",
    "    if not isinstance(response, Classification):\n",
    "        raise ValueError(\"Unexpected response format from OpenAI API.\")\n",
    "    return response.is_opposite\n",
    "\n",
    "# Example usage of is_opposite function\n",
    "text_a = \"Techvify duoc thanh lap vao nam 2019.\"\n",
    "text_b = \"Techvify khong duoc thanh lap vao nam 2019.\"\n",
    "start_time = timeit.default_timer()\n",
    "result = is_opposite(text_a, text_b)\n",
    "end_time = timeit.default_timer()\n",
    "print(f\"Are the sentences '{text_a}' and '{text_b}' opposites? {result}\")\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86872446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity (ground vs numerical different): 0.01769427443252656\n",
      "Similarity (ground vs factually different): 0.9181386012136104\n",
      "Similarity (ground vs both different): 0.002465423564789788\n",
      "Similarity (ground vs rephrased numerical different): 0.8375647165885765\n",
      "Similarity (ground vs rephrased factually different): 0.014765807284835194\n",
      "Similarity (ground vs rephrased both different): 0.7492907358704025\n"
     ]
    }
   ],
   "source": [
    "# Test numerical difference\n",
    "import re\n",
    "\n",
    "NumberLike = int | float\n",
    "\n",
    "def extract_numbers(text: str) -> list[NumberLike] | None:\n",
    "    \"\"\"Extract numbers from a given text.\"\"\"\n",
    "    number_strings = re.findall(r'\\d+\\.?\\d*', text)\n",
    "    if not number_strings:\n",
    "        return None\n",
    "    numbers = [float(num) if '.' in num else int(num) for num in number_strings]\n",
    "    return numbers\n",
    "\n",
    "sentences_num = [\n",
    "    \"Techvify is a software company founded in 2019. It has 200 employees and a revenue of 10 million USD.\",\n",
    "    \"Techvify is a software company founded in 2021. It has 250 employees and a revenue of 12 million USD.\",\n",
    "    \"Techvify is an auditing company founded in 2019. It has 200 employees and a revenue of 10 million USD.\",\n",
    "    \"Techvify is an auditing company founded in 2030. It has 500 employees and a revenue of 50 million USD.\",\n",
    "    # Rephrased version to test robustness\n",
    "    \"In 2019, Techvify was established as a software firm with a workforce of 200 and generated revenues amounting to 10 million USD.\",\n",
    "    \"In 2021, Techvify was established as a software firm with a workforce of 250 and generated revenues amounting to 12 million USD.\",\n",
    "    \"In 2019, Techvify was established as an auditing firm with a workforce of 200 and generated revenues amounting to 10 million USD.\",\n",
    "]\n",
    "\n",
    "embedding_num = embedding_model.embed_texts(sentences_num)\n",
    "\n",
    "ground_truth = embedding_num[0]\n",
    "numerical_different_y = embedding_num[1]\n",
    "factually_different_y = embedding_num[2]\n",
    "factual_and_numerical_different_y = embedding_num[3]\n",
    "\n",
    "rephrase_numerical = embedding_num[4]\n",
    "rephrase_factual = embedding_num[5]\n",
    "rephrase_both = embedding_num[6]\n",
    "\n",
    "def absolute_difference(text1: str, text2: str) -> float:\n",
    "    nums1 = extract_numbers(text1)\n",
    "    nums2 = extract_numbers(text2)\n",
    "    embeddings = embedding_model.embed_texts([text1, text2])\n",
    "    sim = cosine_similarity(embeddings[0], embeddings[1])\n",
    "    if not nums1 or not nums2:\n",
    "        return sim\n",
    "    diff = sum(abs(a - b) for a, b in zip(nums1, nums2))\n",
    "    return sim / (1 + diff)  # Penalize similarity by absolute difference\n",
    "\n",
    "sim_ground_numerical = absolute_difference(sentences_num[0], sentences_num[1])\n",
    "sim_ground_factually = absolute_difference(sentences_num[0], sentences_num[2])\n",
    "sim_ground_both = absolute_difference(sentences_num[0], sentences_num[3])\n",
    "sim_rephrase_numerical = absolute_difference(sentences_num[0], sentences_num[4])\n",
    "sim_rephrase_factually = absolute_difference(sentences_num[0], sentences_num[5])\n",
    "sim_rephrase_both = absolute_difference(sentences_num[0], sentences_num[6])\n",
    "\n",
    "print(f\"Similarity (ground vs numerical different): {sim_ground_numerical}\")\n",
    "print(f\"Similarity (ground vs factually different): {sim_ground_factually}\")\n",
    "print(f\"Similarity (ground vs both different): {sim_ground_both}\")\n",
    "print(f\"Similarity (ground vs rephrased numerical different): {sim_rephrase_numerical}\")\n",
    "print(f\"Similarity (ground vs rephrased factually different): {sim_rephrase_factually}\")\n",
    "print(f\"Similarity (ground vs rephrased both different): {sim_rephrase_both}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamic-tool-router (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
